曾经火热的Graph Embedding和GNN在推荐系统上还有前途吗？ -微信公众号：王喆的机器学习笔记（wangzhenotes）
GNN的收益来源是什么？



我们做推荐系统的优化，一定要清楚每次优化的效果收益来源是什么。一般来说，收益总是来源于样本、特征和模型三个方向的一个或多个。但归根到底，可以再精炼成两个方面，收益要么来源于信息的增加（样本、特征），要么来源于信息利用能力的增强（模型）。



比如说，一个电影推荐系统，从来没有利用过电影中的演员信息，这时候把演员的信息加入到推荐系统中，很大概率能够带来效果的提升，因为这部分信息是新鲜的，系统从未学习过的知识，这就是增量信息带来的收益。



再比如说，我们的推荐模型本来是一个简单的MLP模型，把所有特征通过MLP进行交叉。但用户的行为是一个时间序列，是有前后关联性的，那么改成sequence model就能够更好的表达用户的行为及背后兴趣的变化，这部分的收益就是信息利用能力增强带来的。



说回到主题GNN。GNN能给推荐系统带来收益，主要是哪个方面呢？



我们拿一个电影阿甘正传的knowledge graph来说，它的相关导演，演员，风格的信息肯定是重要的。但对于一个成熟推荐系统来说，肯定是已经通过其他形式学习过这些信息了，比如直接把这些side information进行Embedding化之后喂给模型。我们没有必要一定使用GNN来学习这些知识，所以GNN的收益不来自于增量信息。



图片


那么GNN如果有收益的话，就一定来自于信息利用能力的增强。我们拿一个比较经典的GNN方案RippleNet来说，它一层层的从中心节点扩展学习到周围节点，有二跳、三跳关联关系的学习能力。本质上来说，它利用了knowledge graph点与点之间的拓扑结构，并把拓扑结构中蕴含的关系信息编码到Embedding中去，可以说GNN增强了对知识图谱中关系结构的利用能力，这才是GNN的主要收益来源。



图片


如果说RippleNet的结构还比较复杂的话，早期基于Random Walk的Graph Embedding生成方案更加纯粹的利用了节点间的拓扑结构。比如Node2vec分别基于BFS和DFS随机游走生成序列后，再进行Embedding编码。所以本质上，Node2vec没有引入任何新的知识信息，而是增强了对关系结构的利用能力。



图片


图片


GNN对拓扑结构的利用，对于推荐系统的收益够不够大？



知道了GNN的收益来源，我们就要回答下一个问题，就是这部分收益对于推荐系统来说重不重要。这里也要分两种应用场景进行讨论。



对于行为信息比较丰富的推荐系统来说，比如说抖音、小红书，其大量的用户行为之间的协同关系就可以充分表征内容的相似性了，它不再那么需要知识本体和属性间的连接来补充这种相似性。更何况，现在主流的推荐系统也已经通过直接添加特征的方式学习过知识图谱包含的知识了，由GNN提供的增量就更加微不足道了。



另一方面，对于一些纯知识性的推荐系统，比如说豆瓣、IMDB、知网等，这些网站中知识的链接是非常重要的，知识间二度、三度的关联也是有价值的。而且它缺乏足够多的用户互动信息来覆盖表达物品之间的相似性，那么GNN就是有价值的。



有的朋友可能会说，我们把用户和物品之间的行为也加入图中，不久可以把知识、行为和图结构一起编码了吗？看起来会让生成的Graph Embedding包含更充分的信息，推荐效果肯定会有提高。这个分析是有道理的，早期Pinterest也通过这一方式获得了收益，但这种超大规模的图训练也存在一些致命的问题。



图片


GNN在实际应用中的一些致命问题



首先，实事求是的讲，主流的深度学习训练框架对于图数据的训练并不友好。我们是可以通过一些工程手段讲图数据转换成序列数据进行处理，但这需要比较重度的投入。而且由于要维护整个知识图谱的拓扑结构并在其上采样，GNN的训练成本往往很高，进一步增加了工程投入。



其次，GNN训练得到的Graph Embedding的实时性比较差，它的训练也无法做到目前主流深度学习模型的实时更新。因此GNN不可能作为推荐主模型来使用，只能把生成的Graph Embedding用于召回和特征输入。这让GNN的重要性大打折扣。



在深度学习推荐系统早期，大家的实时性都比较差，训练成本没有打下来的时候，GNN还有一定的优势，但如今主流的推荐模型都是实时更新的情况下，GNN的成本和实时性的问题进一步加大了产生绝对正收益的难度，让本来收益来源基础就比较薄弱的方案更加难以打平。



图片


GNN的未来在哪里？



大模型的出现可以说是对GNN的降维打击。如果说曾经GNN对于知识图谱的学习还可谓是有独特优势，在大模型出现之后，GNN在该方向上的优势也荡然无存。大模型对于开放世界知识的全量学习，几乎可以吊打GNN对个别领域的知识学习。特别是多模态大模型几乎可以对文本、图片、音频、视频等任意信息进行同一空间内的Embedding化，更是让GNN的未来更加暗淡。



图片


图片


关于技术更迭的思考



GNN曾经在学术界是非常火热的研究方向，但实话实说，在工业界却鲜有成功应用。这是业界和学界对于“价值”判断的不同导致的。站在工程师的角度，我们要有火眼金睛，敏锐的分清哪些是看上去很美的方案，哪些是一针见血的方案，它们之间是有本质不同的。最重要的判断依据还是对于收益来源的精准分析。这里面有理性的成分，也有技术直觉的成分。玄学一点来说，这种直觉才是算法工程师应该建立的护城河。



就像“击败雅虎的不会是另一个门户网站，击败google的也不会是另一个搜索引擎”一样，淘汰一个技术的也不会是它的下一版，而是另一个维度的新方案。大模型毫无疑问在知识的广度和利用能力上，大大超出基于知识图谱的GNN，也就当之无愧的成为推荐系统新的更强大的信息输入源。
